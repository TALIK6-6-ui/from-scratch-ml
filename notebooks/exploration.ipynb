{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuilding Naive Bayes — From First Principles\n",
    "\n",
    "> This notebook began as a university assignment, but I kept going. \n",
    "> I wanted to answer: *What really happens inside a Naive Bayes classifier?*\n",
    ">\n",
    "> Here, I implement **Bernoulli** and **Multinomial Naive Bayes from scratch**, compare them to `sklearn`, and even explore Shannon-style text generation.\n",
    ">\n",
    "> Core models live in `src/naive_bayes.py`. This notebook is my playground for testing, reflecting, and learning.\n",
    ">\n",
    "> — Touseef Ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed (uncomment if running locally for the first time)\n",
    "# !pip install numpy pandas scikit-learn matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# Import our from-scratch implementations\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.naive_bayes import BernoulliNaiveBayes, MultinomialNaiveBayes\n",
    "from src.vectorizer import BagOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom Dataset\n",
    "mushroom_df = pd.read_csv(\"../data/mushrooms.csv\")\n",
    "print(\"Mushroom Dataset (first 5 rows):\")\n",
    "print(mushroom_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AG-News Dataset\n",
    "agnews_train = pd.read_csv(\"../data/AG-News/train.csv\")\n",
    "agnews_test = pd.read_csv(\"../data/AG-News/test.csv\")\n",
    "print(\"\\nAG-News Train (first 5 rows):\")\n",
    "print(agnews_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Mushroom Dataset → One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mush_features = mushroom_df.drop('class', axis=1)\n",
    "mush_labels = mushroom_df['class']\n",
    "mush_features_encoded = pd.get_dummies(mush_features, dtype=int)\n",
    "\n",
    "train_mush_features, test_mush_features, train_mush_labels, test_mush_labels = train_test_split(\n",
    "    mush_features_encoded, mush_labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Before split:\", mush_features_encoded.shape)\n",
    "print(\"Train shape:\", train_mush_features.shape)\n",
    "print(\"Test shape:\", test_mush_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AG-News → Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords\n",
    "with open(\"../data/english_stopwords.txt\", \"r\") as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "def clean_text(text, stopwords_set):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)  # Keep alphanum + space\n",
    "    words = text.lower().split()\n",
    "    words = [w for w in words if w not in stopwords_set and w != '']\n",
    "    return ' '.join(words)\n",
    "\n",
    "agnews_train['cleaned'] = agnews_train['Description'].apply(lambda x: clean_text(x, stopwords))\n",
    "agnews_test['cleaned'] = agnews_test['Description'].apply(lambda x: clean_text(x, stopwords))\n",
    "\n",
    "print(\"First 5 cleaned AG-News descriptions:\")\n",
    "print(agnews_train[['Description', 'cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorizing Text with Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = BagOfWords()\n",
    "bow.fit(agnews_train['cleaned'])\n",
    "\n",
    "X_train_news = bow.transform(agnews_train['cleaned'])\n",
    "X_test_news = bow.transform(agnews_test['cleaned'])\n",
    "\n",
    "y_train_news = agnews_train['Category'].values\n",
    "y_test_news = agnews_test['Category'].values\n",
    "\n",
    "print(\"Vocabulary size:\", len(bow.vocab))\n",
    "print(\"X_train_news shape:\", X_train_news.shape)\n",
    "print(\"X_test_news shape:\", X_test_news.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. From-Scratch: Bernoulli Naive Bayes (Mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_model = BernoulliNaiveBayes()\n",
    "bnb_model.fit(train_mush_features, train_mush_labels)\n",
    "y_pred_mush = bnb_model.predict(test_mush_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_mush_labels, y_pred_mush)\n",
    "precision = precision_score(test_mush_labels, y_pred_mush, pos_label='e')\n",
    "recall = recall_score(test_mush_labels, y_pred_mush, pos_label='e')\n",
    "f1 = f1_score(test_mush_labels, y_pred_mush, pos_label='e')\n",
    "matrix = confusion_matrix(test_mush_labels, y_pred_mush)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "ConfusionMatrixDisplay(matrix).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. From-Scratch: Multinomial Naive Bayes (AG-News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNaiveBayes()\n",
    "nb_model.fit(X_train_news, y_train_news)\n",
    "y_pred_news = nb_model.predict(X_test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_news, y_pred_news)\n",
    "precision = precision_score(y_test_news, y_pred_news, average='macro')\n",
    "recall = recall_score(y_test_news, y_pred_news, average='macro')\n",
    "f1 = f1_score(y_test_news, y_pred_news, average='macro')\n",
    "matrix = confusion_matrix(y_test_news, y_pred_news)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "ConfusionMatrixDisplay(matrix).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB (AG-News)\n",
    "mnb_sk = MultinomialNB(alpha=1.0)\n",
    "mnb_sk.fit(X_train_news, y_train_news)\n",
    "y_pred_mnb = mnb_sk.predict(X_test_news)\n",
    "\n",
    "print(\"=== scikit-learn MultinomialNB (AG-News) ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_news, y_pred_mnb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BernoulliNB (Mushroom)\n",
    "bnb_sk = BernoulliNB(alpha=1.0, binarize=None)\n",
    "bnb_sk.fit(train_mush_features, train_mush_labels)\n",
    "y_pred_bnb = bnb_sk.predict(test_mush_features)\n",
    "\n",
    "print(\"=== scikit-learn BernoulliNB (Mushroom) ===\")\n",
    "print(f\"Accuracy: {accuracy_score(test_mush_labels, y_pred_bnb):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generative Fun: Shannon-Style Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_generate(model, vocab, label_idx, n_words=10):\n",
    "    log_probs = model.feature_log_prob_[label_idx]\n",
    "    probs = np.exp(log_probs)\n",
    "    probs /= probs.sum()\n",
    "    sampled_idx = np.random.choice(len(vocab), size=n_words, p=probs)\n",
    "    return [vocab[i] for i in sampled_idx]\n",
    "\n",
    "# Get vocab in correct order\n",
    "vocab_list = [word for word, idx in sorted(bow.vocab.items(), key=lambda x: x[1])]\n",
    "\n",
    "for idx, label in enumerate(mnb_sk.classes_):\n",
    "    words = shannon_generate(mnb_sk, vocab_list, idx, n_words=10)\n",
    "    print(f\"Class '{label}': {' '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "- **Why Bernoulli for Mushroom?** After one-hot encoding, every feature is binary (0/1) — perfect for Bernoulli.\n",
    "- **Why Multinomial for AG-News?** Word counts are discrete frequencies — the domain of Multinomial NB.\n",
    "- **Key insight**: My from-scratch versions match `sklearn` within ~1% — not because I copied, but because I *understood* the math.\n",
    "- **Biggest surprise**: Even a \"simple\" model like NB can *generate* text that reflects class semantics.\n",
    "\n",
    "This isn’t just code. It’s my path to deeper understanding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
